--pour 64 bits
#wget https://github.com/frekele/oracle-java/releases/download/8u212-b10/jdk-8u212-linux-x64.tar.gz     
--pour 32 bits
#wget https://github.com/frekele/oracle-java/releases/download/8u212-b10/jdk-8u212-linux-i586.tar.gz
#tar zxvf jdk-8u212-linux-x64.tar.gz  ou #tar zxvf jdk-8u212-linux-i586.tar.gz
#su
#mv jdk1.8.0_212  /usr/java   --attention au nom du repertoire après décompression

--Ajouter groupe hadoop et user hduser
#groupadd hadoop
#adduser  -G hadoop hduser
#passwd hduser
#su - hduser

--Configuration ssh pour activer un login sans mot de pass
#ssh-keygen -t rsa -P ""
#cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
#chmod 0600 ~/.ssh/authorized_keys
--verification
#ssh localhost
#exit

--Télécharger hadoop
#wget https://archive.apache.org/dist/hadoop/core/hadoop-2.9.2/hadoop-2.9.2.tar.gz
#tar xzf hadoop-2.9.2.tar.gz
#su
#mv hadoop-2.9.2 /opt/hadoop
#su - hduser
--Définir Variables d'environement en editant ~/.bashrc
export JAVA_HOME=/usr/java/
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_HOME=/opt/hadoop/
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib/native"
export HADOOP_CLASSPATH=$(hadoop classpath)
export HADOOP_CLASSPATH=$JAVA_HOME/jre/lib:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

--Appliquer la définition des variables
#source ~/.bashrc
#su
--editer le fichier $HADOOP_HOME/etc/hadoop/hadoop-env.sh  et définir la variable JAVA_HOME. Changer le path de java selon son installation sur le système.
export JAVA_HOME=/usr/java/

#mkdir -p /opt/hadoop/hadoopdata/namenode
#mkdir -p /opt/hadoop/hadoopdata/datanode
#chown -R hduser:hadoop  /opt/hadoop

--Editer les fichiers de configuration
$ cd $HADOOP_HOME/etc/hadoop

Edit core-site.xml

	<configuration>
	<property>
	  <name>fs.default.name</name>
	    <value>hdfs://localhost:9000</value>
	</property>
	</configuration>

Edit hdfs-site.xml

	<configuration>
	<property>
	 <name>dfs.replication</name>
	 <value>1</value>
	</property>

	<property>
	  <name>dfs.name.dir</name>
	    <value>file:/opt/hadoop/hadoopdata/namenode</value>
	</property>

	<property>
	  <name>dfs.data.dir</name>
	    <value>file:/opt/hadoop/hadoopdata/datanode</value>
	</property>
	</configuration>

#mv mapred-site.xml.template mapred-site.xml
Edit mapred-site.xml

	<configuration>
	 <property>
	  <name>mapreduce.framework.name</name>
	   <value>yarn</value>
	 </property>
	</configuration>

Edit yarn-site.xml

	<configuration>
	 <property>
	  <name>yarn.nodemanager.aux-services</name>
	    <value>mapreduce_shuffle</value>
	 </property>
	</configuration>
#su - hduser
--Formatage du Namenode
#hdfs namenode -format

--Démmarage des services hdfs et yarn
#start-dfs.sh
#start-yarn.sh
--Vérification
#jps
--http://localhost:50070
--http://localhost:50095
--http://localhost:8088
--http://localhost:8042
#hdfs dfs -mkdir /user
#hdfs dfs -mkdir /user/hduser
#hdfs dfs chown hduser /user/hduser
#hdfs dfs -mkdir data  -- data sera creé dans /user/hduser
#hdfs dfs -mkdir results  -- data sera creé dans /user/hduser

-- Pour installer Sublime txt
#sudo rpm -v --import https://download.sublimetext.com/sublimehq-rpm-pub.gpg
#sudo yum-config-manager --add-repo https://download.sublimetext.com/rpm/stable/x86_64/sublime-text.repo
#sudo yum install sublime-text    

-- mise a jour de yum 
sudo tee /etc/yum.repos.d/CentOS-Vault.repo >/dev/null << 'EOF'
[base]
name=CentOS-7 - Base
baseurl=http://vault.centos.org/7.9.2009/os/x86_64/
gpgcheck=0
enabled=1

[updates]
name=CentOS-7 - Updates
baseurl=http://vault.centos.org/7.9.2009/updates/x86_64/
gpgcheck=0
enabled=1

[extras]
name=CentOS-7 - Extras
baseurl=http://vault.centos.org/7.9.2009/extras/x86_64/
gpgcheck=0
enabled=1
EOF

Désactive tous les mirrorlists de CentOS (sinon yum restera cassé)

Éditer :

sudo nano /etc/yum.repos.d/CentOS-Base.repo


Dans tout le fichier :

Mets # devant toutes les lignes mirrorlist=

Décommente baseurl= et modifie comme ceci :

baseurl=http://vault.centos.org/7.9.2009/os/x86_64/


Fais pareil pour les sections :

[base]

[updates]

[extras]

Ensuite :

sudo yum clean all
sudo yum makecache

sudo yum install gtk3 libX11 libXcomposite libXcursor libXdamage libXext libXi libXrandr libXScrnSaver libXtst freetype freetype-devel fontconfig

/*
  Master M1 BD2C
	Année 2018/2019
  --
  TP1: exemple de programme Hadoop - compteur d'occurences de mots.
  --
  WCountMap.java: classe driver (contient le main du programme).
*/

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.IntWritable;


// Note classe Driver (contient le main du programme Hadoop).
public class WCount {
    // Le main du programme.
    public static void main(String[] args) throws Exception {
        // Créé un object de configuration Hadoop.
        Configuration conf = new Configuration();

        // Permet à Hadoop de lire ses arguments génériques, récupère les arguments restants dans ourArgs.
        String[] ourArgs = new GenericOptionsParser(conf, args).getRemainingArgs();

        // Obtient un nouvel objet Job: une tâche Hadoop. On fourni la configuration Hadoop ainsi qu'une description
        // textuelle de la tâche.
        Job job = Job.getInstance(conf, "Compteur de mots v1.0");

        // Défini les classes driver, map et reduce.
        job.setJarByClass(WCount.class);
        job.setMapperClass(WCountMap.class);
        job.setReducerClass(WCountReduce.class);

        // Défini types clefs/valeurs de notre programme Hadoop.
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // Défini les fichiers d'entrée du programme et le répertoire des résultats.
        // On se sert du premier et du deuxième argument restants pour permettre à l'utilisateur de les spécifier
        // lors de l'exécution.
        FileInputFormat.addInputPath(job, new Path(ourArgs[0]));
        FileOutputFormat.setOutputPath(job, new Path(ourArgs[1]));

        // On lance la tâche Hadoop. Si elle s'est effectuée correctement, on renvoie 0. Sinon, on renvoie -1.
        if (job.waitForCompletion(true))
            System.exit(0);
        System.exit(-1);
    }
}


/*
  Master M1 BD2C
	Année 2018/2019
  --
  TP1: exemple de programme Hadoop - compteur d'occurences de mots.
  --
  WCountMap.java: classe MAP.
*/

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.IntWritable;

import java.util.StringTokenizer;

import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;


// Notre classe MAP.
public class WCountMap extends Mapper<Object, Text, Text, IntWritable> {
    private static final IntWritable ONE = new IntWritable(1);

    // La fonction MAP elle-même.
    protected void map(Object key, Text value, Context context) throws IOException, InterruptedException {

        // Un StringTokenizer va nous permettre de parcourir chacun des mots de la ligne qui est passée
        // à notre opération MAP.
        StringTokenizer tok = new StringTokenizer(value.toString(), " ");
        while (tok.hasMoreTokens()) {
            Text word = new Text(tok.nextToken());
            // On renvoie notre couple (clef;valeur): le mot courant suivi de la valeur 1 (définie dans la constante ONE).
            context.write(word, ONE);
        }
    }
}

/*
  Master M1 BD2C
	Année 2018/2019
  --
  TP1: exemple de programme Hadoop - compteur d'occurences de mots.
  --
  WCountReduce.java: classe REDUCE.
*/

import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Reducer;

import java.util.Iterator;
import java.io.IOException;


// Notre classe REDUCE - templatée avec un type générique K pour la clef, un type de valeur IntWritable, et un type de retour
// (le retour final de la fonction Reduce) Text.
public class WCountReduce extends Reducer<Text, IntWritable, Text, Text> {

    // La fonction REDUCE elle-même. Les arguments: la clef key (d'un type générique K), un Iterable de toutes les valeurs
    // qui sont associées à la clef en question, et le contexte Hadoop (un handle qui nous permet de renvoyer le résultat à Hadoop).
    public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {

        // Pour parcourir toutes les valeurs associées à la clef fournie.
        Iterator<IntWritable> i = values.iterator();
        int count = 0;
        while (i.hasNext())   // Pour chaque valeur...
            count += i.next().get();    // ...on l'ajoute au total.
        // On renvoie le couple (clef;valeur) constitué de notre clef key et du total, au format Text.
        context.write(key, new Text(count + " occurences."));
    }
}

===poeme.txt====
celui qui croyait au ciel
celui qui ny croyait pas
tous deux adoraient la belle
prisonniere des soldats
lequel montait a lechelle
et lequel guettait en bas
celui qui croyait au ciel
celui qui ny croyait pas
quimporte comment sappelle
cette clarte sur leur pas
que lun fut de la chapelle
et lautre sy derobât
celui qui croyait au ciel
celui qui ny croyait pas
tous les deux etaient fideles
des levres du coeur des bras
et tous les deux disaient quelle
vive et qui vivra verra
celui qui croyait au ciel
celui qui ny croyait pas
quand les bles sont sous la grele
fou qui fait le delicat
fou qui songe a ses querelles
au coeur du commun combat
celui qui croyait au ciel
celui qui ny croyait pas
du haut de la citadelle
la sentinelle tira
par deux fois et lun chancelle
lautre tombe qui mourra
celui qui croyait au ciel
celui qui ny croyait pas
ils sont en prison lequel
a le plus triste grabat
lequel plus que lautre gele
lequel prefere les rats
celui qui croyait au ciel
celui qui ny croyait pas
un rebelle est un rebelle
deux sanglots font un seul glas
et quand vient laube cruelle
passent de vie a trepas
celui qui croyait au ciel
celui qui ny croyait pas
repetant le nom de celle
quaucun des deux ne trompa
et leur sang rouge ruisselle
meme couleur meme eclat
celui qui croyait au ciel
celui qui ny croyait pas
il coule il coule il se mele
a la terre quil aima
pour qua la saison nouvelle
murisse un raisin muscat
celui qui croyait au ciel
celui qui ny croyait pas
lun court et lautre a des ailes
de bretagne ou du jura
et framboise ou mirabelle
le grillon rechantera
dites flute ou violoncelle
le double amour qui brula
lalouette et lhirondelle
la rose et le reseda 

--on édite WCount.java WCountMap.java WCountReduce.java 
--et on les place dans le répertoire ~/WordCountJava qu’il faut créer au préalable

--Compilation  dans le répertoire ~/WordCountJava
#hadoop com.sun.tools.javac.Main  WordCountJava/WCount*.java
#mkdir -p WordCountJava/build
#mv WordCountJava/WCount*.class WordCountJava/build
#jar -cvf wc.jar -C WordCountJava/build  .
--Préparation des données sur HDFS

-- télécharger le fichier poeme.txt dans dans votre répertoire personnel  /home/hduser/WordCountJava (~/WordCountJava)
-- le fichier poeme.txt est fourni comme ressource de ce chapitre
# cd ~
#hdfs dfs -put WordCountJava/poeme.txt data   (data par défaut est /user/hduser/data   déjà creé dans l'atalier installerHadoop) 
--(results par défaut est /user/hduser/results   déjà creé dans l'atalier installerHadoop) 

--Exécution
#hadoop jar wc.jar WCount  data results/wcoutput  --wcoutput sera creé automatiquement  et contiendra les fichiers résultat part-r-xxxxx

--Affichage des résultats
#hdfs dfs -ls results/wcoutput
#hdfs dfs -cat results/wcoutput/part-r-00000
